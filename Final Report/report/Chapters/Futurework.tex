While performing a comparative analysis of a model, the Bi-LSTM model produces efficient prediction compare to other models that modelslanning to improve the model and produce more accurate results with the help of a more complex model and using a transformer. There are other complex models like CNN-LSTM and Conv-LSTM may produce good result compare to Bi-LSTM, also using Bi-Directional LSTM encoder-decoder we can reduce the error on training and testing data.

We are planning to apply the same model on a cloud platform like AWS, google cloud, Azure. First, collect metric information of VM on which your application is running, once we collect all the data apply those data to Bi-directional LSTM using machine learning service i.e. for AWS there is on service Amazon Sage Maker which helps to run the model on AWS and integrate service with your application based on the real-time load of CPU usage it predict the future workload for small period i.e 2 to 5 hr and based on prediction adjust the scheduling of VM. If CPU load is too low then it will freeze the VM or model predict the spike in future CPU usage it provisioned some VM in advance to save the time of provision resources when there is a spike of CPU usage in the applications.  When you train to predict the other performance metrics of the model then you can save lots of resources that are not used by the application and using resource provisioned in advance it may save your time when load increase.
